{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tutorial_perceptron_simple.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNrf0f89FmE/qb/fAGnDM/x"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUIb2_CEMXgH"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyhUugaeM26q"
      },
      "source": [
        "inputs = np.array([[0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n",
        "y = np.array([[0], [1], [1], [1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPqpiVWrRTdc"
      },
      "source": [
        "def sigmoide(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "def mse(output, target):\n",
        "  return np.mean((output - target) ** 2) / 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdHgVkeYGz6O"
      },
      "source": [
        "1/2 (output - y) ^ 2 \\\\\n",
        "1/2 (sigm(z) - y) ^ 2 \\\\\n",
        "1/2 (sigm(inputs * W) - y) ^ 2 \\\\\n",
        "Derivada W: \\\\\n",
        "(output - y) * (sigmoide(z)*(1 - sigmoide(z)) * inputs \\\\"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEcssQvhDD-s"
      },
      "source": [
        "W = np.random.normal(scale=0.5, size=(3, 1))\n",
        "errors = []\n",
        "epochs = 10000\n",
        "lr = 0.6\n",
        "errormse = 1\n",
        "while errormse > 0.001:\n",
        "  #forward\n",
        "  z = np.dot(inputs, W)\n",
        "  output = sigmoide(z)\n",
        "  errormse = mse(output, y)\n",
        "  errors.append(errormse)\n",
        "  # backpropagation\n",
        "  error = output - y\n",
        "  delta = error * (sigmoide(z) * (1 - sigmoide(z)))\n",
        "  derivada = np.dot(inputs.T, delta)\n",
        "  # gradient descent\n",
        "  W -= derivada * lr\n",
        "\n",
        "z = np.dot(inputs, W)\n",
        "output = sigmoide(z)\n",
        "for j in range(len(output)):\n",
        "  print(round(output[j, 0], 4))\n",
        "\n",
        "x_axis = range(len(errors))\n",
        "plt.plot(x_axis, errors)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}